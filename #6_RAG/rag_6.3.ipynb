{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 Embedding에 대해 얘기해보자.<br>\n",
    "우리는 지금까지 Loading과 Transforming을 했다. 이제 Embedding을 해볼 시간이다. 쉽게 말하자면, Embedding의 의미는, 사람이 읽는 텍스트를 컴퓨터가 이해할 수 있는 숫자들로 변환하는 작업이다. 하지만 이것은 쉽게 얘기를 한 것이고, 이것보다는 조금 더 멋지고 복잡한 일이다.\n",
    "<br>\n",
    "<br>\n",
    "먼저 Vector에 대해 얘기해보자.<br>\n",
    "벡터, 좀 더 정확히는 Vectorization(벡터화) 작업을 하게 될 건데, 우리가 만든 문서마다 각각의 벡터를 만들어 줄 것이다. 이전에 우리가 split처리를 해준 문서마다 embed작업을 해서 벡터를 만들어 준다는 말이다.<br>\n",
    "이때 우리가 사용할 openAI의 embedding모델을 보게 된건데, 그것이 우리에게 최소 1000차원을 갖는 벡터를 제공해준다. 2차원 벡터 3차원 벡터는 들어봤어도 1000차원은 상상이 안갈 것이다. 그래서 일단 3차원 벡터에 대해서만 생각해보자. 그 다음, 몇몇 단어를 embed하는 것을 연습해 볼 것이다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 단어(word)에 embed작업을 할 것이다. 3차원 벡터를 가지고 연습 해보자.\n",
    "\n",
    "            Masculinity(남성성)   |   Femininity(여성성)   |   Royalty(왕족성)\n",
    "    king |       0.9            |       0.1             |       1.0         \n",
    "    queen|      0.1             |       0.9             |       1.0         \n",
    "    man  |      0.9             |       0.1             |       0.0         \n",
    "\n",
    "위는 3차원 벡터를 가지는 단어를 embed해본 것이다.<br>\n",
    "남성성, 여성성, 왕족성 이라는 특성을 각 단어(king, queen, man)가 얼마나 반영하는지 평가를 해서 0.0~1.0까지의 점수를 매겼다. 이렇게 벡터(카테고리)를 정하고 각 단어가 의미론적으로 그 벡터와 얼마나 연관이 있는지 평가를 하는것을 embed라고 한다. 여기서 남성성, 여성성, 왕족성은 벡터이고 3개니까 3차원이 된다.\n",
    "\n",
    "다시 생각해봐도, 벡터가 천개 이상의 차원을 갖는다는건, 정말 많은거 같다. 그정도면 상상할 수 있는 모든 분류를 넣을 수 있을것이다.\n",
    "\n",
    "단어를 이런 차원들로 표현할 때의 멋진점이 뭐냐면, 다른 단어를 얻기 위해 가진 단어를 가지고 연산을 할 수 있다는 사실이다. 예를들어, king - man 같은 뺄셈을 수행하면 어떤 값을 얻게 될까?<br><br>\n",
    "\n",
    "??? = king - man<br>\n",
    "=> Masculinity: 0.0<br>\n",
    "=> Femininity: 0.0<br>\n",
    "=> Royalty: 1.0<br><br>\n",
    "\n",
    "이 단어가 무엇일까??<br>\n",
    "바로 단어 'royal'임을 알 수 있다. 비록 성별은 몰라도 왕족이 확실함은 알 수 있다. \n",
    "\n",
    "이번에는 woman이라는 단어를 평가한 뒤 woman + royal을 해보자.<br><br>\n",
    "\n",
    "    woman |     0.1             |       0.9             |       0.0         \n",
    "\n",
    "    woman + royal |     0.1     |       0.9             |       1.0         \n",
    "\n",
    "이 woman + royal의 단어는 무엇일까? 바로 'queen'이 되는것을 알 수 있다.<br>\n",
    "우리는 단어끼리 연산을 할 수 있게 됐다!! 단어를 숫자들로 치환한 덕분이다. 이게 바로 우리들이 하게 될 작업이다. 우리는 문서들을 전부 숫자들로 바꿔줄 것이다. 그렇게 되면 우리는 벡터에 대한 search(검색)작업을 할 수 있게 된다. 즉, 지슷한 벡터를 찾을 수 있게 된다는 것이다. 이를 벡터들이 서로 '가깝다'고 표현한다.<br>\n",
    "이게 바로 많은 추천 알고리즘들이 작동하는 방식이다.(넷플릭스나 유튜브 같은 알고리즘을 말하는거) 예를들어 우리가 영화에 대한 database를 가지고 있다면, 그 안의 배우, 주제, 길이, 개봉년도, 무엇이든지 벡터화 할 수 있다. 그것들을 우리가 방금 했던 좌표들에 넣으면 우리는 어떤 영화들이 서로 가까운지 알 수 있게 된다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
